{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT281 - Laboratorio N°10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1'></a>\n",
    "## I.- Problema 01\n",
    "\n",
    "\n",
    "<img src=\"https://www.goodnewsnetwork.org/wp-content/uploads/2019/07/immunotherapy-vaccine-attacks-cancer-cells-immune-blood-Fotolia_purchased.jpg\" width=\"360\" height=\"360\" align=\"center\"/>\n",
    "\n",
    "\n",
    "El **cáncer de mama**  es una proliferación maligna de las células epiteliales que revisten los conductos o lobulillos mamarios. Es una enfermedad clonal; donde una célula individual producto de una serie de mutaciones somáticas o de línea germinal adquiere la capacidad de dividirse sin control ni orden, haciendo que se reproduzca hasta formar un tumor. El tumor resultante, que comienza como anomalía leve, pasa a ser grave, invade tejidos vecinos y, finalmente, se propaga a otras partes del cuerpo.\n",
    "\n",
    "El conjunto de datos se denomina `BC.csv`, el cual contine la información de distintos pacientes con tumosres (benignos o malignos) y algunas características del mismo.\n",
    "\n",
    "\n",
    "Las características se calculan a partir de una imagen digitalizada de un aspirado con aguja fina (FNA) de una masa mamaria. Describen las características de los núcleos celulares presentes en la imagen.\n",
    "Los detalles se puede encontrar en [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "\n",
    "Lo primero será cargar el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302          1        17.99         10.38          122.80     1001.0   \n",
       "1    842517          1        20.57         17.77          132.90     1326.0   \n",
       "2  84300903          1        19.69         21.25          130.00     1203.0   \n",
       "3  84348301          1        11.42         20.38           77.58      386.1   \n",
       "4  84358402          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cargar datos\n",
    "df = pd.read_csv(os.path.join(\"data\",\"BC.csv\"), sep=\",\")\n",
    "df['diagnosis'] = df['diagnosis'] .replace({'M':1,'B':0}) # target \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basado en la información presentada responda las siguientes preguntas:\n",
    "\n",
    "1. Realice un análisis exploratorio del conjunto de datos.\n",
    "1. Normalizar las variables numéricas con el método **StandardScaler**.\n",
    "3. Realizar un método de reducción de dimensionalidad visto en clases.\n",
    "4. Aplique al menos tres modelos de clasificación distintos. Para cada uno de los modelos escogidos, realice una optimización de los hiperparámetros. además, calcule las respectivas métricas. Concluya.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Análisis exploratorio del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columna</th>\n",
       "      <th>unicos</th>\n",
       "      <th>vacios</th>\n",
       "      <th>% vacios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>569</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>479</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>522</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>539</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>concavity_mean</td>\n",
       "      <td>537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>symmetry_mean</td>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fractal_dimension_mean</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>radius_se</td>\n",
       "      <td>540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>texture_se</td>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>perimeter_se</td>\n",
       "      <td>533</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>area_se</td>\n",
       "      <td>528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>smoothness_se</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>compactness_se</td>\n",
       "      <td>541</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>concavity_se</td>\n",
       "      <td>533</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>concave points_se</td>\n",
       "      <td>507</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>symmetry_se</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fractal_dimension_se</td>\n",
       "      <td>545</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>457</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>511</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>539</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>492</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>symmetry_worst</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>fractal_dimension_worst</td>\n",
       "      <td>535</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    columna  unicos  vacios  % vacios\n",
       "0                        id     569       0       0.0\n",
       "1                 diagnosis       2       0       0.0\n",
       "2               radius_mean     456       0       0.0\n",
       "3              texture_mean     479       0       0.0\n",
       "4            perimeter_mean     522       0       0.0\n",
       "5                 area_mean     539       0       0.0\n",
       "6           smoothness_mean     474       0       0.0\n",
       "7          compactness_mean     537       0       0.0\n",
       "8            concavity_mean     537       0       0.0\n",
       "9       concave points_mean     542       0       0.0\n",
       "10            symmetry_mean     432       0       0.0\n",
       "11   fractal_dimension_mean     499       0       0.0\n",
       "12                radius_se     540       0       0.0\n",
       "13               texture_se     519       0       0.0\n",
       "14             perimeter_se     533       0       0.0\n",
       "15                  area_se     528       0       0.0\n",
       "16            smoothness_se     547       0       0.0\n",
       "17           compactness_se     541       0       0.0\n",
       "18             concavity_se     533       0       0.0\n",
       "19        concave points_se     507       0       0.0\n",
       "20              symmetry_se     498       0       0.0\n",
       "21     fractal_dimension_se     545       0       0.0\n",
       "22             radius_worst     457       0       0.0\n",
       "23            texture_worst     511       0       0.0\n",
       "24          perimeter_worst     514       0       0.0\n",
       "25               area_worst     544       0       0.0\n",
       "26         smoothness_worst     411       0       0.0\n",
       "27        compactness_worst     529       0       0.0\n",
       "28          concavity_worst     539       0       0.0\n",
       "29     concave points_worst     492       0       0.0\n",
       "30           symmetry_worst     500       0       0.0\n",
       "31  fractal_dimension_worst     535       0       0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resumen de la informacion\n",
    "\n",
    "def resumen_por_columna(df,cols):\n",
    "    pd_series = df[cols]\n",
    "    \n",
    "    # elementos distintos \n",
    "    l_unique = pd_series.unique()\n",
    "    \n",
    "    # elementos vacios\n",
    "    \n",
    "    l_vacios = pd_series[pd_series.isna()]\n",
    "    \n",
    "    df_info = pd.DataFrame({\n",
    "        'columna': [cols],\n",
    "        'unicos': [len(l_unique)],\n",
    "        'vacios': [len(l_vacios)]\n",
    "    })\n",
    "    \n",
    "    return df_info\n",
    "\n",
    "frames = []\n",
    "\n",
    "for col in df.columns:\n",
    "    aux_df = resumen_por_columna(df,col)\n",
    "    frames.append(aux_df)\n",
    "    \n",
    "df_info = pd.concat(frames).reset_index(drop=True)\n",
    "df_info['% vacios'] = df_info['vacios']/len(df)\n",
    "df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Normalizar las variables numéricas con el método StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926424</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>-0.312589</td>\n",
       "      <td>...</td>\n",
       "      <td>1.901185</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.752563</td>\n",
       "      <td>2.015301</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>-0.273318</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926682</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>-0.217664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536720</td>\n",
       "      <td>2.047399</td>\n",
       "      <td>1.421940</td>\n",
       "      <td>1.494959</td>\n",
       "      <td>-0.691230</td>\n",
       "      <td>-0.394820</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926954</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>-0.809117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561361</td>\n",
       "      <td>1.374854</td>\n",
       "      <td>0.579001</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>-0.809587</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927241</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>2.137194</td>\n",
       "      <td>...</td>\n",
       "      <td>1.961239</td>\n",
       "      <td>2.237926</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>1.653171</td>\n",
       "      <td>1.430427</td>\n",
       "      <td>3.904848</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92751</th>\n",
       "      <td>-0.770609</td>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>-1.150752</td>\n",
       "      <td>-1.114873</td>\n",
       "      <td>-1.261820</td>\n",
       "      <td>-0.820070</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.410893</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>-1.432735</td>\n",
       "      <td>-1.075813</td>\n",
       "      <td>-1.859019</td>\n",
       "      <td>-1.207552</td>\n",
       "      <td>-1.305831</td>\n",
       "      <td>-1.745063</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.751207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                          \n",
       "842302     1.297676     1.097064     -2.073335        1.269934   0.984375   \n",
       "842517     1.297676     1.829821     -0.353632        1.685955   1.908708   \n",
       "84300903   1.297676     1.579888      0.456187        1.566503   1.558884   \n",
       "84348301   1.297676    -0.768909      0.253732       -0.592687  -0.764464   \n",
       "84358402   1.297676     1.750297     -1.151816        1.776573   1.826229   \n",
       "...             ...          ...           ...             ...        ...   \n",
       "926424     1.297676     2.110995      0.721473        2.060786   2.343856   \n",
       "926682     1.297676     1.704854      2.085134        1.615931   1.723842   \n",
       "926954     1.297676     0.702284      2.045574        0.672676   0.577953   \n",
       "927241     1.297676     1.838341      2.336457        1.982524   1.735218   \n",
       "92751     -0.770609    -1.808401      1.221792       -1.814389  -1.347789   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                            \n",
       "842302           1.568466          3.283515        2.652874   \n",
       "842517          -0.826962         -0.487072       -0.023846   \n",
       "84300903         0.942210          1.052926        1.363478   \n",
       "84348301         3.283553          3.402909        1.915897   \n",
       "84358402         0.280372          0.539340        1.371011   \n",
       "...                   ...               ...             ...   \n",
       "926424           1.041842          0.219060        1.947285   \n",
       "926682           0.102458         -0.017833        0.693043   \n",
       "926954          -0.840484         -0.038680        0.046588   \n",
       "927241           1.525767          3.272144        3.296944   \n",
       "92751           -3.112085         -1.150752       -1.114873   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  radius_worst  \\\n",
       "id                                            ...                 \n",
       "842302               2.532475       2.217515  ...      1.886690   \n",
       "842517               0.548144       0.001392  ...      1.805927   \n",
       "84300903             2.037231       0.939685  ...      1.511870   \n",
       "84348301             1.451707       2.867383  ...     -0.281464   \n",
       "84358402             1.428493      -0.009560  ...      1.298575   \n",
       "...                       ...            ...  ...           ...   \n",
       "926424               2.320965      -0.312589  ...      1.901185   \n",
       "926682               1.263669      -0.217664  ...      1.536720   \n",
       "926954               0.105777      -0.809117  ...      0.561361   \n",
       "927241               2.658866       2.137194  ...      1.961239   \n",
       "92751               -1.261820      -0.820070  ...     -1.410893   \n",
       "\n",
       "          texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "id                                                                       \n",
       "842302        -1.359293         2.303601    2.001237          1.307686   \n",
       "842517        -0.369203         1.535126    1.890489         -0.375612   \n",
       "84300903      -0.023974         1.347475    1.456285          0.527407   \n",
       "84348301       0.133984        -0.249939   -0.550021          3.394275   \n",
       "84358402      -1.466770         1.338539    1.220724          0.220556   \n",
       "...                 ...              ...         ...               ...   \n",
       "926424         0.117700         1.752563    2.015301          0.378365   \n",
       "926682         2.047399         1.421940    1.494959         -0.691230   \n",
       "926954         1.374854         0.579001    0.427906         -0.809587   \n",
       "927241         2.237926         2.303601    1.653171          1.430427   \n",
       "92751          0.764190        -1.432735   -1.075813         -1.859019   \n",
       "\n",
       "          compactness_worst  concavity_worst  concave points_worst  \\\n",
       "id                                                                   \n",
       "842302             2.616665         2.109526              2.296076   \n",
       "842517            -0.430444        -0.146749              1.087084   \n",
       "84300903           1.082932         0.854974              1.955000   \n",
       "84348301           3.893397         1.989588              2.175786   \n",
       "84358402          -0.313395         0.613179              0.729259   \n",
       "...                     ...              ...                   ...   \n",
       "926424            -0.273318         0.664512              1.629151   \n",
       "926682            -0.394820         0.236573              0.733827   \n",
       "926954             0.350735         0.326767              0.414069   \n",
       "927241             3.904848         3.197605              2.289985   \n",
       "92751             -1.207552        -1.305831             -1.745063   \n",
       "\n",
       "          symmetry_worst  fractal_dimension_worst  \n",
       "id                                                 \n",
       "842302          2.750622                 1.937015  \n",
       "842517         -0.243890                 0.281190  \n",
       "84300903        1.152255                 0.201391  \n",
       "84348301        6.046041                 4.935010  \n",
       "84358402       -0.868353                -0.397100  \n",
       "...                  ...                      ...  \n",
       "926424         -1.360158                -0.709091  \n",
       "926682         -0.531855                -0.973978  \n",
       "926954         -1.104549                -0.318409  \n",
       "927241          1.919083                 2.219635  \n",
       "92751          -0.048138                -0.751207  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df.set_index('id', inplace = True)\n",
    "scaler = StandardScaler()\n",
    "columns = df.columns\n",
    "df[columns] = scaler.fit_transform(df[columns])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.108857e-15</td>\n",
       "      <td>-1.256562e-16</td>\n",
       "      <td>1.049736e-16</td>\n",
       "      <td>-1.272171e-16</td>\n",
       "      <td>-1.900452e-16</td>\n",
       "      <td>-8.226187e-16</td>\n",
       "      <td>2.419467e-16</td>\n",
       "      <td>-1.315097e-16</td>\n",
       "      <td>-8.780323e-17</td>\n",
       "      <td>1.957036e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.956924e-16</td>\n",
       "      <td>-1.834112e-17</td>\n",
       "      <td>-4.015534e-16</td>\n",
       "      <td>-2.848727e-17</td>\n",
       "      <td>-2.251665e-16</td>\n",
       "      <td>-2.579464e-16</td>\n",
       "      <td>1.143393e-16</td>\n",
       "      <td>3.203842e-16</td>\n",
       "      <td>1.783381e-16</td>\n",
       "      <td>-6.436952e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.706085e-01</td>\n",
       "      <td>-2.029648e+00</td>\n",
       "      <td>-2.229249e+00</td>\n",
       "      <td>-1.984504e+00</td>\n",
       "      <td>-1.454443e+00</td>\n",
       "      <td>-3.112085e+00</td>\n",
       "      <td>-1.610136e+00</td>\n",
       "      <td>-1.114873e+00</td>\n",
       "      <td>-1.261820e+00</td>\n",
       "      <td>-2.744117e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.726901e+00</td>\n",
       "      <td>-2.223994e+00</td>\n",
       "      <td>-1.693361e+00</td>\n",
       "      <td>-1.222423e+00</td>\n",
       "      <td>-2.682695e+00</td>\n",
       "      <td>-1.443878e+00</td>\n",
       "      <td>-1.305831e+00</td>\n",
       "      <td>-1.745063e+00</td>\n",
       "      <td>-2.160960e+00</td>\n",
       "      <td>-1.601839e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.706085e-01</td>\n",
       "      <td>-6.893853e-01</td>\n",
       "      <td>-7.259631e-01</td>\n",
       "      <td>-6.919555e-01</td>\n",
       "      <td>-6.671955e-01</td>\n",
       "      <td>-7.109628e-01</td>\n",
       "      <td>-7.470860e-01</td>\n",
       "      <td>-7.437479e-01</td>\n",
       "      <td>-7.379438e-01</td>\n",
       "      <td>-7.032397e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.749213e-01</td>\n",
       "      <td>-7.486293e-01</td>\n",
       "      <td>-6.895783e-01</td>\n",
       "      <td>-6.421359e-01</td>\n",
       "      <td>-6.912304e-01</td>\n",
       "      <td>-6.810833e-01</td>\n",
       "      <td>-7.565142e-01</td>\n",
       "      <td>-7.563999e-01</td>\n",
       "      <td>-6.418637e-01</td>\n",
       "      <td>-6.919118e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-7.706085e-01</td>\n",
       "      <td>-2.150816e-01</td>\n",
       "      <td>-1.046362e-01</td>\n",
       "      <td>-2.359800e-01</td>\n",
       "      <td>-2.951869e-01</td>\n",
       "      <td>-3.489108e-02</td>\n",
       "      <td>-2.219405e-01</td>\n",
       "      <td>-3.422399e-01</td>\n",
       "      <td>-3.977212e-01</td>\n",
       "      <td>-7.162650e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.690395e-01</td>\n",
       "      <td>-4.351564e-02</td>\n",
       "      <td>-2.859802e-01</td>\n",
       "      <td>-3.411812e-01</td>\n",
       "      <td>-4.684277e-02</td>\n",
       "      <td>-2.695009e-01</td>\n",
       "      <td>-2.182321e-01</td>\n",
       "      <td>-2.234689e-01</td>\n",
       "      <td>-1.274095e-01</td>\n",
       "      <td>-2.164441e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.297676e+00</td>\n",
       "      <td>4.693926e-01</td>\n",
       "      <td>5.841756e-01</td>\n",
       "      <td>4.996769e-01</td>\n",
       "      <td>3.635073e-01</td>\n",
       "      <td>6.361990e-01</td>\n",
       "      <td>4.938569e-01</td>\n",
       "      <td>5.260619e-01</td>\n",
       "      <td>6.469351e-01</td>\n",
       "      <td>5.307792e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.220158e-01</td>\n",
       "      <td>6.583411e-01</td>\n",
       "      <td>5.402790e-01</td>\n",
       "      <td>3.575891e-01</td>\n",
       "      <td>5.975448e-01</td>\n",
       "      <td>5.396688e-01</td>\n",
       "      <td>5.311411e-01</td>\n",
       "      <td>7.125100e-01</td>\n",
       "      <td>4.501382e-01</td>\n",
       "      <td>4.507624e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.297676e+00</td>\n",
       "      <td>3.971288e+00</td>\n",
       "      <td>4.651889e+00</td>\n",
       "      <td>3.976130e+00</td>\n",
       "      <td>5.250529e+00</td>\n",
       "      <td>4.770911e+00</td>\n",
       "      <td>4.568425e+00</td>\n",
       "      <td>4.243589e+00</td>\n",
       "      <td>3.927930e+00</td>\n",
       "      <td>4.484751e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.094189e+00</td>\n",
       "      <td>3.885905e+00</td>\n",
       "      <td>4.287337e+00</td>\n",
       "      <td>5.930172e+00</td>\n",
       "      <td>3.955374e+00</td>\n",
       "      <td>5.112877e+00</td>\n",
       "      <td>4.700669e+00</td>\n",
       "      <td>2.685877e+00</td>\n",
       "      <td>6.046041e+00</td>\n",
       "      <td>6.846856e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          diagnosis   radius_mean  texture_mean  perimeter_mean     area_mean  \\\n",
       "count  5.690000e+02  5.690000e+02  5.690000e+02    5.690000e+02  5.690000e+02   \n",
       "mean   1.108857e-15 -1.256562e-16  1.049736e-16   -1.272171e-16 -1.900452e-16   \n",
       "std    1.000880e+00  1.000880e+00  1.000880e+00    1.000880e+00  1.000880e+00   \n",
       "min   -7.706085e-01 -2.029648e+00 -2.229249e+00   -1.984504e+00 -1.454443e+00   \n",
       "25%   -7.706085e-01 -6.893853e-01 -7.259631e-01   -6.919555e-01 -6.671955e-01   \n",
       "50%   -7.706085e-01 -2.150816e-01 -1.046362e-01   -2.359800e-01 -2.951869e-01   \n",
       "75%    1.297676e+00  4.693926e-01  5.841756e-01    4.996769e-01  3.635073e-01   \n",
       "max    1.297676e+00  3.971288e+00  4.651889e+00    3.976130e+00  5.250529e+00   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count     5.690000e+02      5.690000e+02    5.690000e+02         5.690000e+02   \n",
       "mean     -8.226187e-16      2.419467e-16   -1.315097e-16        -8.780323e-17   \n",
       "std       1.000880e+00      1.000880e+00    1.000880e+00         1.000880e+00   \n",
       "min      -3.112085e+00     -1.610136e+00   -1.114873e+00        -1.261820e+00   \n",
       "25%      -7.109628e-01     -7.470860e-01   -7.437479e-01        -7.379438e-01   \n",
       "50%      -3.489108e-02     -2.219405e-01   -3.422399e-01        -3.977212e-01   \n",
       "75%       6.361990e-01      4.938569e-01    5.260619e-01         6.469351e-01   \n",
       "max       4.770911e+00      4.568425e+00    4.243589e+00         3.927930e+00   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count   5.690000e+02  ...  5.690000e+02   5.690000e+02     5.690000e+02   \n",
       "mean    1.957036e-16  ... -7.956924e-16  -1.834112e-17    -4.015534e-16   \n",
       "std     1.000880e+00  ...  1.000880e+00   1.000880e+00     1.000880e+00   \n",
       "min    -2.744117e+00  ... -1.726901e+00  -2.223994e+00    -1.693361e+00   \n",
       "25%    -7.032397e-01  ... -6.749213e-01  -7.486293e-01    -6.895783e-01   \n",
       "50%    -7.162650e-02  ... -2.690395e-01  -4.351564e-02    -2.859802e-01   \n",
       "75%     5.307792e-01  ...  5.220158e-01   6.583411e-01     5.402790e-01   \n",
       "max     4.484751e+00  ...  4.094189e+00   3.885905e+00     4.287337e+00   \n",
       "\n",
       "         area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count  5.690000e+02      5.690000e+02       5.690000e+02     5.690000e+02   \n",
       "mean  -2.848727e-17     -2.251665e-16      -2.579464e-16     1.143393e-16   \n",
       "std    1.000880e+00      1.000880e+00       1.000880e+00     1.000880e+00   \n",
       "min   -1.222423e+00     -2.682695e+00      -1.443878e+00    -1.305831e+00   \n",
       "25%   -6.421359e-01     -6.912304e-01      -6.810833e-01    -7.565142e-01   \n",
       "50%   -3.411812e-01     -4.684277e-02      -2.695009e-01    -2.182321e-01   \n",
       "75%    3.575891e-01      5.975448e-01       5.396688e-01     5.311411e-01   \n",
       "max    5.930172e+00      3.955374e+00       5.112877e+00     4.700669e+00   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count          5.690000e+02    5.690000e+02             5.690000e+02  \n",
       "mean           3.203842e-16    1.783381e-16            -6.436952e-16  \n",
       "std            1.000880e+00    1.000880e+00             1.000880e+00  \n",
       "min           -1.745063e+00   -2.160960e+00            -1.601839e+00  \n",
       "25%           -7.563999e-01   -6.418637e-01            -6.919118e-01  \n",
       "50%           -2.234689e-01   -1.274095e-01            -2.164441e-01  \n",
       "75%            7.125100e-01    4.501382e-01             4.507624e-01  \n",
       "max            2.685877e+00    6.046041e+00             6.846856e+00  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Realizar un método de reducción de dimensionalidad visto en clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PC1</th>\n",
       "      <td>0.216917</td>\n",
       "      <td>0.216399</td>\n",
       "      <td>0.103599</td>\n",
       "      <td>0.224548</td>\n",
       "      <td>0.217965</td>\n",
       "      <td>0.137645</td>\n",
       "      <td>0.231504</td>\n",
       "      <td>0.251222</td>\n",
       "      <td>0.255266</td>\n",
       "      <td>0.133013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225590</td>\n",
       "      <td>0.105019</td>\n",
       "      <td>0.233642</td>\n",
       "      <td>0.221970</td>\n",
       "      <td>0.125301</td>\n",
       "      <td>0.204476</td>\n",
       "      <td>0.223075</td>\n",
       "      <td>0.246288</td>\n",
       "      <td>0.120663</td>\n",
       "      <td>0.126721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC2</th>\n",
       "      <td>-0.077610</td>\n",
       "      <td>-0.226545</td>\n",
       "      <td>-0.058262</td>\n",
       "      <td>-0.207630</td>\n",
       "      <td>-0.223224</td>\n",
       "      <td>0.188760</td>\n",
       "      <td>0.158473</td>\n",
       "      <td>0.067868</td>\n",
       "      <td>-0.027220</td>\n",
       "      <td>0.193220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212896</td>\n",
       "      <td>-0.045135</td>\n",
       "      <td>-0.192592</td>\n",
       "      <td>-0.211887</td>\n",
       "      <td>0.172476</td>\n",
       "      <td>0.147663</td>\n",
       "      <td>0.103088</td>\n",
       "      <td>-0.002433</td>\n",
       "      <td>0.142062</td>\n",
       "      <td>0.276449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC3</th>\n",
       "      <td>-0.103826</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.054751</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.040151</td>\n",
       "      <td>-0.102835</td>\n",
       "      <td>-0.067146</td>\n",
       "      <td>0.010477</td>\n",
       "      <td>-0.017048</td>\n",
       "      <td>-0.040310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037380</td>\n",
       "      <td>-0.052989</td>\n",
       "      <td>-0.038072</td>\n",
       "      <td>-0.001176</td>\n",
       "      <td>-0.261677</td>\n",
       "      <td>-0.231049</td>\n",
       "      <td>-0.167051</td>\n",
       "      <td>-0.162709</td>\n",
       "      <td>-0.272450</td>\n",
       "      <td>-0.232692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC4</th>\n",
       "      <td>0.098083</td>\n",
       "      <td>-0.050448</td>\n",
       "      <td>0.599537</td>\n",
       "      <td>-0.051245</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>-0.150488</td>\n",
       "      <td>-0.040499</td>\n",
       "      <td>-0.027710</td>\n",
       "      <td>-0.070256</td>\n",
       "      <td>-0.059519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024256</td>\n",
       "      <td>0.627598</td>\n",
       "      <td>-0.023544</td>\n",
       "      <td>-0.033893</td>\n",
       "      <td>-0.013843</td>\n",
       "      <td>0.074232</td>\n",
       "      <td>0.057160</td>\n",
       "      <td>-0.017570</td>\n",
       "      <td>0.034978</td>\n",
       "      <td>0.065305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC5</th>\n",
       "      <td>-0.080783</td>\n",
       "      <td>0.041751</td>\n",
       "      <td>-0.020448</td>\n",
       "      <td>0.041566</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>-0.367173</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.089617</td>\n",
       "      <td>-0.041530</td>\n",
       "      <td>-0.304188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>-0.060711</td>\n",
       "      <td>0.013919</td>\n",
       "      <td>-0.021218</td>\n",
       "      <td>-0.319865</td>\n",
       "      <td>0.133701</td>\n",
       "      <td>0.197269</td>\n",
       "      <td>0.049157</td>\n",
       "      <td>-0.235644</td>\n",
       "      <td>0.102373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC6</th>\n",
       "      <td>-0.012050</td>\n",
       "      <td>0.019239</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>0.017864</td>\n",
       "      <td>-0.001176</td>\n",
       "      <td>-0.284964</td>\n",
       "      <td>-0.013160</td>\n",
       "      <td>-0.009063</td>\n",
       "      <td>-0.051440</td>\n",
       "      <td>0.357697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>-0.047470</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>-0.024072</td>\n",
       "      <td>-0.367792</td>\n",
       "      <td>0.048659</td>\n",
       "      <td>0.028636</td>\n",
       "      <td>-0.030438</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>-0.079585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC7</th>\n",
       "      <td>-0.146157</td>\n",
       "      <td>-0.113375</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>-0.102689</td>\n",
       "      <td>-0.040115</td>\n",
       "      <td>-0.116836</td>\n",
       "      <td>0.049011</td>\n",
       "      <td>-0.095753</td>\n",
       "      <td>-0.136517</td>\n",
       "      <td>-0.076269</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>0.028407</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.076971</td>\n",
       "      <td>-0.101091</td>\n",
       "      <td>0.146559</td>\n",
       "      <td>-0.055441</td>\n",
       "      <td>-0.160569</td>\n",
       "      <td>-0.018002</td>\n",
       "      <td>0.366420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC8</th>\n",
       "      <td>0.182757</td>\n",
       "      <td>-0.026495</td>\n",
       "      <td>0.100374</td>\n",
       "      <td>-0.038649</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>-0.309993</td>\n",
       "      <td>-0.169954</td>\n",
       "      <td>-0.091642</td>\n",
       "      <td>-0.166744</td>\n",
       "      <td>-0.247066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.066456</td>\n",
       "      <td>0.183575</td>\n",
       "      <td>0.077066</td>\n",
       "      <td>0.059216</td>\n",
       "      <td>-0.044375</td>\n",
       "      <td>0.218388</td>\n",
       "      <td>0.079321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC9</th>\n",
       "      <td>0.000313</td>\n",
       "      <td>-0.223138</td>\n",
       "      <td>0.112614</td>\n",
       "      <td>-0.223768</td>\n",
       "      <td>-0.195631</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>-0.167854</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>-0.111962</td>\n",
       "      <td>0.256053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112160</td>\n",
       "      <td>0.103298</td>\n",
       "      <td>-0.109637</td>\n",
       "      <td>-0.080771</td>\n",
       "      <td>0.112247</td>\n",
       "      <td>-0.100710</td>\n",
       "      <td>0.161875</td>\n",
       "      <td>0.060495</td>\n",
       "      <td>0.064585</td>\n",
       "      <td>-0.134133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC10</th>\n",
       "      <td>-0.050214</td>\n",
       "      <td>0.099453</td>\n",
       "      <td>0.253798</td>\n",
       "      <td>0.091105</td>\n",
       "      <td>0.081497</td>\n",
       "      <td>-0.064997</td>\n",
       "      <td>0.021275</td>\n",
       "      <td>-0.128370</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.572036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077559</td>\n",
       "      <td>0.035055</td>\n",
       "      <td>0.052315</td>\n",
       "      <td>0.073405</td>\n",
       "      <td>-0.122732</td>\n",
       "      <td>-0.166581</td>\n",
       "      <td>-0.305747</td>\n",
       "      <td>-0.079473</td>\n",
       "      <td>-0.027994</td>\n",
       "      <td>0.003144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC11</th>\n",
       "      <td>0.644348</td>\n",
       "      <td>-0.035308</td>\n",
       "      <td>-0.312407</td>\n",
       "      <td>-0.061975</td>\n",
       "      <td>-0.056667</td>\n",
       "      <td>-0.156225</td>\n",
       "      <td>-0.283750</td>\n",
       "      <td>-0.124784</td>\n",
       "      <td>-0.071731</td>\n",
       "      <td>0.039102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070346</td>\n",
       "      <td>-0.050863</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.044393</td>\n",
       "      <td>0.028185</td>\n",
       "      <td>-0.144872</td>\n",
       "      <td>-0.043640</td>\n",
       "      <td>0.054516</td>\n",
       "      <td>0.103596</td>\n",
       "      <td>0.212860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC12</th>\n",
       "      <td>-0.319011</td>\n",
       "      <td>0.065831</td>\n",
       "      <td>-0.164216</td>\n",
       "      <td>0.053592</td>\n",
       "      <td>0.157256</td>\n",
       "      <td>-0.063839</td>\n",
       "      <td>-0.186413</td>\n",
       "      <td>0.224746</td>\n",
       "      <td>-0.037546</td>\n",
       "      <td>0.175679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073643</td>\n",
       "      <td>0.036117</td>\n",
       "      <td>0.041119</td>\n",
       "      <td>0.178885</td>\n",
       "      <td>0.132278</td>\n",
       "      <td>-0.153087</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>-0.179310</td>\n",
       "      <td>0.106118</td>\n",
       "      <td>0.012189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC13</th>\n",
       "      <td>0.033950</td>\n",
       "      <td>0.046930</td>\n",
       "      <td>0.236735</td>\n",
       "      <td>0.032347</td>\n",
       "      <td>0.054517</td>\n",
       "      <td>0.308729</td>\n",
       "      <td>-0.122536</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>0.034510</td>\n",
       "      <td>-0.304136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047742</td>\n",
       "      <td>0.081004</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.049534</td>\n",
       "      <td>0.064997</td>\n",
       "      <td>-0.373290</td>\n",
       "      <td>-0.106783</td>\n",
       "      <td>-0.045481</td>\n",
       "      <td>0.059305</td>\n",
       "      <td>-0.016622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC14</th>\n",
       "      <td>0.479306</td>\n",
       "      <td>-0.031764</td>\n",
       "      <td>0.158721</td>\n",
       "      <td>-0.005569</td>\n",
       "      <td>-0.014468</td>\n",
       "      <td>-0.054774</td>\n",
       "      <td>0.144017</td>\n",
       "      <td>0.357356</td>\n",
       "      <td>0.186109</td>\n",
       "      <td>0.131084</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149257</td>\n",
       "      <td>-0.141678</td>\n",
       "      <td>-0.125409</td>\n",
       "      <td>-0.174743</td>\n",
       "      <td>-0.287638</td>\n",
       "      <td>-0.070345</td>\n",
       "      <td>0.178584</td>\n",
       "      <td>-0.156674</td>\n",
       "      <td>-0.275073</td>\n",
       "      <td>-0.045277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC15</th>\n",
       "      <td>0.247454</td>\n",
       "      <td>0.049141</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.039825</td>\n",
       "      <td>-0.024268</td>\n",
       "      <td>0.447148</td>\n",
       "      <td>-0.005070</td>\n",
       "      <td>-0.117800</td>\n",
       "      <td>-0.189877</td>\n",
       "      <td>0.054697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016201</td>\n",
       "      <td>-0.001295</td>\n",
       "      <td>-0.031343</td>\n",
       "      <td>-0.095597</td>\n",
       "      <td>0.082897</td>\n",
       "      <td>0.146612</td>\n",
       "      <td>-0.017262</td>\n",
       "      <td>-0.299688</td>\n",
       "      <td>-0.070032</td>\n",
       "      <td>-0.184463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC16</th>\n",
       "      <td>-0.177559</td>\n",
       "      <td>0.060292</td>\n",
       "      <td>0.107724</td>\n",
       "      <td>0.050731</td>\n",
       "      <td>0.039645</td>\n",
       "      <td>0.068678</td>\n",
       "      <td>-0.230613</td>\n",
       "      <td>0.117805</td>\n",
       "      <td>0.223101</td>\n",
       "      <td>0.070235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184770</td>\n",
       "      <td>-0.076332</td>\n",
       "      <td>-0.191612</td>\n",
       "      <td>-0.274360</td>\n",
       "      <td>-0.015709</td>\n",
       "      <td>0.050450</td>\n",
       "      <td>0.189266</td>\n",
       "      <td>0.233485</td>\n",
       "      <td>-0.112068</td>\n",
       "      <td>0.283282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC17</th>\n",
       "      <td>-0.004666</td>\n",
       "      <td>-0.149680</td>\n",
       "      <td>-0.156678</td>\n",
       "      <td>-0.113616</td>\n",
       "      <td>-0.130859</td>\n",
       "      <td>-0.204569</td>\n",
       "      <td>0.167573</td>\n",
       "      <td>0.270682</td>\n",
       "      <td>0.383142</td>\n",
       "      <td>-0.163907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>0.185183</td>\n",
       "      <td>-0.057511</td>\n",
       "      <td>-0.093276</td>\n",
       "      <td>0.145950</td>\n",
       "      <td>-0.153151</td>\n",
       "      <td>-0.213312</td>\n",
       "      <td>0.181851</td>\n",
       "      <td>0.257087</td>\n",
       "      <td>-0.401982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC18</th>\n",
       "      <td>0.038610</td>\n",
       "      <td>0.197432</td>\n",
       "      <td>-0.039399</td>\n",
       "      <td>0.188199</td>\n",
       "      <td>0.221691</td>\n",
       "      <td>0.196542</td>\n",
       "      <td>-0.006556</td>\n",
       "      <td>-0.002575</td>\n",
       "      <td>0.027113</td>\n",
       "      <td>-0.211588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208786</td>\n",
       "      <td>0.061204</td>\n",
       "      <td>-0.205632</td>\n",
       "      <td>-0.275177</td>\n",
       "      <td>-0.318497</td>\n",
       "      <td>-0.002391</td>\n",
       "      <td>-0.189061</td>\n",
       "      <td>-0.112558</td>\n",
       "      <td>0.460005</td>\n",
       "      <td>0.145690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC19</th>\n",
       "      <td>0.060721</td>\n",
       "      <td>0.237828</td>\n",
       "      <td>-0.039633</td>\n",
       "      <td>0.251509</td>\n",
       "      <td>0.247223</td>\n",
       "      <td>-0.370872</td>\n",
       "      <td>0.106999</td>\n",
       "      <td>-0.028200</td>\n",
       "      <td>-0.140224</td>\n",
       "      <td>0.122710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200897</td>\n",
       "      <td>0.033339</td>\n",
       "      <td>-0.153101</td>\n",
       "      <td>-0.310060</td>\n",
       "      <td>0.525957</td>\n",
       "      <td>-0.074135</td>\n",
       "      <td>-0.136643</td>\n",
       "      <td>-0.060363</td>\n",
       "      <td>-0.183916</td>\n",
       "      <td>0.019066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC20</th>\n",
       "      <td>0.091934</td>\n",
       "      <td>-0.132340</td>\n",
       "      <td>-0.061754</td>\n",
       "      <td>-0.145192</td>\n",
       "      <td>0.135322</td>\n",
       "      <td>0.040125</td>\n",
       "      <td>-0.278472</td>\n",
       "      <td>-0.017324</td>\n",
       "      <td>0.107648</td>\n",
       "      <td>0.103389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095975</td>\n",
       "      <td>0.103046</td>\n",
       "      <td>-0.169022</td>\n",
       "      <td>0.295173</td>\n",
       "      <td>-0.058793</td>\n",
       "      <td>-0.070552</td>\n",
       "      <td>-0.024722</td>\n",
       "      <td>0.224301</td>\n",
       "      <td>-0.183729</td>\n",
       "      <td>0.020863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC21</th>\n",
       "      <td>-0.036663</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>0.409311</td>\n",
       "      <td>-0.011275</td>\n",
       "      <td>0.075921</td>\n",
       "      <td>-0.054666</td>\n",
       "      <td>-0.376684</td>\n",
       "      <td>0.032495</td>\n",
       "      <td>0.207534</td>\n",
       "      <td>-0.062788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>-0.515647</td>\n",
       "      <td>-0.028254</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.178604</td>\n",
       "      <td>-0.136218</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>-0.020894</td>\n",
       "      <td>0.185120</td>\n",
       "      <td>0.048356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC22</th>\n",
       "      <td>0.053280</td>\n",
       "      <td>-0.077194</td>\n",
       "      <td>0.299062</td>\n",
       "      <td>-0.071314</td>\n",
       "      <td>-0.055442</td>\n",
       "      <td>-0.115582</td>\n",
       "      <td>0.363627</td>\n",
       "      <td>-0.001976</td>\n",
       "      <td>-0.077282</td>\n",
       "      <td>-0.061677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>-0.414072</td>\n",
       "      <td>-0.106594</td>\n",
       "      <td>0.155108</td>\n",
       "      <td>0.110487</td>\n",
       "      <td>0.243848</td>\n",
       "      <td>-0.196425</td>\n",
       "      <td>-0.008384</td>\n",
       "      <td>0.080174</td>\n",
       "      <td>-0.088861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC23</th>\n",
       "      <td>0.024393</td>\n",
       "      <td>0.071284</td>\n",
       "      <td>0.102355</td>\n",
       "      <td>0.072599</td>\n",
       "      <td>0.089804</td>\n",
       "      <td>0.053471</td>\n",
       "      <td>-0.050101</td>\n",
       "      <td>-0.195409</td>\n",
       "      <td>-0.332997</td>\n",
       "      <td>-0.019312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093321</td>\n",
       "      <td>-0.126396</td>\n",
       "      <td>-0.001150</td>\n",
       "      <td>-0.090188</td>\n",
       "      <td>-0.066481</td>\n",
       "      <td>0.058120</td>\n",
       "      <td>0.437124</td>\n",
       "      <td>0.309404</td>\n",
       "      <td>0.091207</td>\n",
       "      <td>-0.486212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC24</th>\n",
       "      <td>0.017395</td>\n",
       "      <td>-0.094671</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.037292</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>-0.024344</td>\n",
       "      <td>0.069094</td>\n",
       "      <td>0.319126</td>\n",
       "      <td>-0.070642</td>\n",
       "      <td>-0.051779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054999</td>\n",
       "      <td>-0.012633</td>\n",
       "      <td>0.052442</td>\n",
       "      <td>0.189161</td>\n",
       "      <td>0.093161</td>\n",
       "      <td>-0.140817</td>\n",
       "      <td>0.294124</td>\n",
       "      <td>-0.564949</td>\n",
       "      <td>0.120336</td>\n",
       "      <td>-0.011978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC25</th>\n",
       "      <td>-0.049430</td>\n",
       "      <td>0.184560</td>\n",
       "      <td>-0.096296</td>\n",
       "      <td>0.116974</td>\n",
       "      <td>-0.066963</td>\n",
       "      <td>-0.064128</td>\n",
       "      <td>0.096526</td>\n",
       "      <td>-0.057003</td>\n",
       "      <td>-0.058657</td>\n",
       "      <td>-0.020463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160464</td>\n",
       "      <td>0.123378</td>\n",
       "      <td>-0.230731</td>\n",
       "      <td>-0.147167</td>\n",
       "      <td>0.008705</td>\n",
       "      <td>-0.215020</td>\n",
       "      <td>0.296565</td>\n",
       "      <td>-0.086659</td>\n",
       "      <td>0.020248</td>\n",
       "      <td>-0.005937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC26</th>\n",
       "      <td>-0.006814</td>\n",
       "      <td>0.024279</td>\n",
       "      <td>-0.087320</td>\n",
       "      <td>-0.024079</td>\n",
       "      <td>0.209827</td>\n",
       "      <td>-0.030388</td>\n",
       "      <td>-0.395395</td>\n",
       "      <td>0.094071</td>\n",
       "      <td>0.188145</td>\n",
       "      <td>0.023905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066629</td>\n",
       "      <td>0.122403</td>\n",
       "      <td>-0.124423</td>\n",
       "      <td>0.034690</td>\n",
       "      <td>0.048194</td>\n",
       "      <td>0.617521</td>\n",
       "      <td>-0.106681</td>\n",
       "      <td>-0.264477</td>\n",
       "      <td>-0.044098</td>\n",
       "      <td>-0.278049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC27</th>\n",
       "      <td>0.023530</td>\n",
       "      <td>-0.130571</td>\n",
       "      <td>-0.022190</td>\n",
       "      <td>-0.124220</td>\n",
       "      <td>0.342817</td>\n",
       "      <td>-0.039611</td>\n",
       "      <td>0.264186</td>\n",
       "      <td>-0.566541</td>\n",
       "      <td>0.402939</td>\n",
       "      <td>-0.014482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192472</td>\n",
       "      <td>0.029850</td>\n",
       "      <td>-0.230926</td>\n",
       "      <td>0.224242</td>\n",
       "      <td>0.013702</td>\n",
       "      <td>-0.092494</td>\n",
       "      <td>0.264658</td>\n",
       "      <td>-0.146142</td>\n",
       "      <td>0.024166</td>\n",
       "      <td>-0.003982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC28</th>\n",
       "      <td>0.012486</td>\n",
       "      <td>-0.141751</td>\n",
       "      <td>-0.017950</td>\n",
       "      <td>-0.123992</td>\n",
       "      <td>0.486074</td>\n",
       "      <td>0.068129</td>\n",
       "      <td>0.114030</td>\n",
       "      <td>0.336948</td>\n",
       "      <td>-0.438425</td>\n",
       "      <td>-0.015534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190033</td>\n",
       "      <td>0.020490</td>\n",
       "      <td>-0.252843</td>\n",
       "      <td>0.250557</td>\n",
       "      <td>-0.040669</td>\n",
       "      <td>-0.073251</td>\n",
       "      <td>-0.133916</td>\n",
       "      <td>0.223117</td>\n",
       "      <td>0.022636</td>\n",
       "      <td>0.057201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC29</th>\n",
       "      <td>-0.001962</td>\n",
       "      <td>0.212824</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>0.085745</td>\n",
       "      <td>-0.274942</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>-0.006520</td>\n",
       "      <td>0.046109</td>\n",
       "      <td>-0.008582</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411686</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.727969</td>\n",
       "      <td>0.239343</td>\n",
       "      <td>-0.001413</td>\n",
       "      <td>0.048670</td>\n",
       "      <td>-0.017410</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>-0.023158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC30</th>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.206962</td>\n",
       "      <td>-0.010659</td>\n",
       "      <td>0.384042</td>\n",
       "      <td>-0.418906</td>\n",
       "      <td>-0.003334</td>\n",
       "      <td>-0.038592</td>\n",
       "      <td>-0.011767</td>\n",
       "      <td>-0.005089</td>\n",
       "      <td>-0.007519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.639163</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.446577</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.013432</td>\n",
       "      <td>0.034580</td>\n",
       "      <td>0.012879</td>\n",
       "      <td>0.010476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC31</th>\n",
       "      <td>-0.001348</td>\n",
       "      <td>-0.702475</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>0.689191</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>-0.045143</td>\n",
       "      <td>-0.024740</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138186</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>-0.079757</td>\n",
       "      <td>-0.041442</td>\n",
       "      <td>-0.004538</td>\n",
       "      <td>0.012834</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>-0.001678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "PC1    0.216917     0.216399      0.103599        0.224548   0.217965   \n",
       "PC2   -0.077610    -0.226545     -0.058262       -0.207630  -0.223224   \n",
       "PC3   -0.103826     0.002527      0.054751        0.001854   0.040151   \n",
       "PC4    0.098083    -0.050448      0.599537       -0.051245  -0.061116   \n",
       "PC5   -0.080783     0.041751     -0.020448        0.041566   0.014113   \n",
       "PC6   -0.012050     0.019239     -0.030018        0.017864  -0.001176   \n",
       "PC7   -0.146157    -0.113375      0.027502       -0.102689  -0.040115   \n",
       "PC8    0.182757    -0.026495      0.100374       -0.038649   0.013356   \n",
       "PC9    0.000313    -0.223138      0.112614       -0.223768  -0.195631   \n",
       "PC10  -0.050214     0.099453      0.253798        0.091105   0.081497   \n",
       "PC11   0.644348    -0.035308     -0.312407       -0.061975  -0.056667   \n",
       "PC12  -0.319011     0.065831     -0.164216        0.053592   0.157256   \n",
       "PC13   0.033950     0.046930      0.236735        0.032347   0.054517   \n",
       "PC14   0.479306    -0.031764      0.158721       -0.005569  -0.014468   \n",
       "PC15   0.247454     0.049141      0.004391        0.039825  -0.024268   \n",
       "PC16  -0.177559     0.060292      0.107724        0.050731   0.039645   \n",
       "PC17  -0.004666    -0.149680     -0.156678       -0.113616  -0.130859   \n",
       "PC18   0.038610     0.197432     -0.039399        0.188199   0.221691   \n",
       "PC19   0.060721     0.237828     -0.039633        0.251509   0.247223   \n",
       "PC20   0.091934    -0.132340     -0.061754       -0.145192   0.135322   \n",
       "PC21  -0.036663     0.015782      0.409311       -0.011275   0.075921   \n",
       "PC22   0.053280    -0.077194      0.299062       -0.071314  -0.055442   \n",
       "PC23   0.024393     0.071284      0.102355        0.072599   0.089804   \n",
       "PC24   0.017395    -0.094671     -0.000157       -0.037292   0.006013   \n",
       "PC25  -0.049430     0.184560     -0.096296        0.116974  -0.066963   \n",
       "PC26  -0.006814     0.024279     -0.087320       -0.024079   0.209827   \n",
       "PC27   0.023530    -0.130571     -0.022190       -0.124220   0.342817   \n",
       "PC28   0.012486    -0.141751     -0.017950       -0.123992   0.486074   \n",
       "PC29  -0.001962     0.212824     -0.000055        0.085745  -0.274942   \n",
       "PC30   0.005607     0.206962     -0.010659        0.384042  -0.418906   \n",
       "PC31  -0.001348    -0.702475     -0.000213        0.689191   0.033346   \n",
       "\n",
       "      smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "PC1          0.137645          0.231504        0.251222             0.255266   \n",
       "PC2          0.188760          0.158473        0.067868            -0.027220   \n",
       "PC3         -0.102835         -0.067146        0.010477            -0.017048   \n",
       "PC4         -0.150488         -0.040499       -0.027710            -0.070256   \n",
       "PC5         -0.367173          0.016980        0.089617            -0.041530   \n",
       "PC6         -0.284964         -0.013160       -0.009063            -0.051440   \n",
       "PC7         -0.116836          0.049011       -0.095753            -0.136517   \n",
       "PC8         -0.309993         -0.169954       -0.091642            -0.166744   \n",
       "PC9          0.006445         -0.167854        0.040571            -0.111962   \n",
       "PC10        -0.064997          0.021275       -0.128370             0.009735   \n",
       "PC11        -0.156225         -0.283750       -0.124784            -0.071731   \n",
       "PC12        -0.063839         -0.186413        0.224746            -0.037546   \n",
       "PC13         0.308729         -0.122536        0.033529             0.034510   \n",
       "PC14        -0.054774          0.144017        0.357356             0.186109   \n",
       "PC15         0.447148         -0.005070       -0.117800            -0.189877   \n",
       "PC16         0.068678         -0.230613        0.117805             0.223101   \n",
       "PC17        -0.204569          0.167573        0.270682             0.383142   \n",
       "PC18         0.196542         -0.006556       -0.002575             0.027113   \n",
       "PC19        -0.370872          0.106999       -0.028200            -0.140224   \n",
       "PC20         0.040125         -0.278472       -0.017324             0.107648   \n",
       "PC21        -0.054666         -0.376684        0.032495             0.207534   \n",
       "PC22        -0.115582          0.363627       -0.001976            -0.077282   \n",
       "PC23         0.053471         -0.050101       -0.195409            -0.332997   \n",
       "PC24        -0.024344          0.069094        0.319126            -0.070642   \n",
       "PC25        -0.064128          0.096526       -0.057003            -0.058657   \n",
       "PC26        -0.030388         -0.395395        0.094071             0.188145   \n",
       "PC27        -0.039611          0.264186       -0.566541             0.402939   \n",
       "PC28         0.068129          0.114030        0.336948            -0.438425   \n",
       "PC29         0.001431         -0.006520        0.046109            -0.008582   \n",
       "PC30        -0.003334         -0.038592       -0.011767            -0.005089   \n",
       "PC31         0.004837         -0.045143       -0.024740             0.001307   \n",
       "\n",
       "      symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "PC1        0.133013  ...      0.225590       0.105019         0.233642   \n",
       "PC2        0.193220  ...     -0.212896      -0.045135        -0.192592   \n",
       "PC3       -0.040310  ...     -0.037380      -0.052989        -0.038072   \n",
       "PC4       -0.059519  ...     -0.024256       0.627598        -0.023544   \n",
       "PC5       -0.304188  ...      0.001558      -0.060711         0.013919   \n",
       "PC6        0.357697  ...      0.000521      -0.047470         0.009377   \n",
       "PC7       -0.076269  ...     -0.002954       0.028407         0.008165   \n",
       "PC8       -0.247066  ...      0.034180       0.014354         0.019613   \n",
       "PC9        0.256053  ...     -0.112160       0.103298        -0.109637   \n",
       "PC10       0.572036  ...      0.077559       0.035055         0.052315   \n",
       "PC11       0.039102  ...      0.070346      -0.050863         0.019053   \n",
       "PC12       0.175679  ...      0.073643       0.036117         0.041119   \n",
       "PC13      -0.304136  ...      0.047742       0.081004        -0.004220   \n",
       "PC14       0.131084  ...     -0.149257      -0.141678        -0.125409   \n",
       "PC15       0.054697  ...     -0.016201      -0.001295        -0.031343   \n",
       "PC16       0.070235  ...     -0.184770      -0.076332        -0.191612   \n",
       "PC17      -0.163907  ...     -0.084316       0.185183        -0.057511   \n",
       "PC18      -0.211588  ...     -0.208786       0.061204        -0.205632   \n",
       "PC19       0.122710  ...     -0.200897       0.033339        -0.153101   \n",
       "PC20       0.103389  ...     -0.095975       0.103046        -0.169022   \n",
       "PC21      -0.062788  ...      0.004856      -0.515647        -0.028254   \n",
       "PC22      -0.061677  ...      0.014421      -0.414072        -0.106594   \n",
       "PC23      -0.019312  ...     -0.093321      -0.126396        -0.001150   \n",
       "PC24      -0.051779  ...     -0.054999      -0.012633         0.052442   \n",
       "PC25      -0.020463  ...      0.160464       0.123378        -0.230731   \n",
       "PC26       0.023905  ...     -0.066629       0.122403        -0.124423   \n",
       "PC27      -0.014482  ...     -0.192472       0.029850        -0.230926   \n",
       "PC28      -0.015534  ...     -0.190033       0.020490        -0.252843   \n",
       "PC29       0.001396  ...      0.411686      -0.000096        -0.727969   \n",
       "PC30      -0.007519  ...     -0.639163       0.016541         0.023286   \n",
       "PC31       0.001288  ...      0.138186      -0.000903        -0.079757   \n",
       "\n",
       "      area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "PC1     0.221970          0.125301           0.204476         0.223075   \n",
       "PC2    -0.211887          0.172476           0.147663         0.103088   \n",
       "PC3    -0.001176         -0.261677          -0.231049        -0.167051   \n",
       "PC4    -0.033893         -0.013843           0.074232         0.057160   \n",
       "PC5    -0.021218         -0.319865           0.133701         0.197269   \n",
       "PC6    -0.024072         -0.367792           0.048659         0.028636   \n",
       "PC7     0.076971         -0.101091           0.146559        -0.055441   \n",
       "PC8     0.066456          0.183575           0.077066         0.059216   \n",
       "PC9    -0.080771          0.112247          -0.100710         0.161875   \n",
       "PC10    0.073405         -0.122732          -0.166581        -0.305747   \n",
       "PC11    0.044393          0.028185          -0.144872        -0.043640   \n",
       "PC12    0.178885          0.132278          -0.153087         0.237092   \n",
       "PC13    0.049534          0.064997          -0.373290        -0.106783   \n",
       "PC14   -0.174743         -0.287638          -0.070345         0.178584   \n",
       "PC15   -0.095597          0.082897           0.146612        -0.017262   \n",
       "PC16   -0.274360         -0.015709           0.050450         0.189266   \n",
       "PC17   -0.093276          0.145950          -0.153151        -0.213312   \n",
       "PC18   -0.275177         -0.318497          -0.002391        -0.189061   \n",
       "PC19   -0.310060          0.525957          -0.074135        -0.136643   \n",
       "PC20    0.295173         -0.058793          -0.070552        -0.024722   \n",
       "PC21    0.003047          0.178604          -0.136218         0.020377   \n",
       "PC22    0.155108          0.110487           0.243848        -0.196425   \n",
       "PC23   -0.090188         -0.066481           0.058120         0.437124   \n",
       "PC24    0.189161          0.093161          -0.140817         0.294124   \n",
       "PC25   -0.147167          0.008705          -0.215020         0.296565   \n",
       "PC26    0.034690          0.048194           0.617521        -0.106681   \n",
       "PC27    0.224242          0.013702          -0.092494         0.264658   \n",
       "PC28    0.250557         -0.040669          -0.073251        -0.133916   \n",
       "PC29    0.239343         -0.001413           0.048670        -0.017410   \n",
       "PC30    0.446577          0.007100          -0.000013        -0.013432   \n",
       "PC31   -0.041442         -0.004538           0.012834        -0.000175   \n",
       "\n",
       "      concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "PC1               0.246288        0.120663                 0.126721  \n",
       "PC2              -0.002433        0.142062                 0.276449  \n",
       "PC3              -0.162709       -0.272450                -0.232692  \n",
       "PC4              -0.017570        0.034978                 0.065305  \n",
       "PC5               0.049157       -0.235644                 0.102373  \n",
       "PC6              -0.030438        0.500246                -0.079585  \n",
       "PC7              -0.160569       -0.018002                 0.366420  \n",
       "PC8              -0.044375        0.218388                 0.079321  \n",
       "PC9               0.060495        0.064585                -0.134133  \n",
       "PC10             -0.079473       -0.027994                 0.003144  \n",
       "PC11              0.054516        0.103596                 0.212860  \n",
       "PC12             -0.179310        0.106118                 0.012189  \n",
       "PC13             -0.045481        0.059305                -0.016622  \n",
       "PC14             -0.156674       -0.275073                -0.045277  \n",
       "PC15             -0.299688       -0.070032                -0.184463  \n",
       "PC16              0.233485       -0.112068                 0.283282  \n",
       "PC17              0.181851        0.257087                -0.401982  \n",
       "PC18             -0.112558        0.460005                 0.145690  \n",
       "PC19             -0.060363       -0.183916                 0.019066  \n",
       "PC20              0.224301       -0.183729                 0.020863  \n",
       "PC21             -0.020894        0.185120                 0.048356  \n",
       "PC22             -0.008384        0.080174                -0.088861  \n",
       "PC23              0.309404        0.091207                -0.486212  \n",
       "PC24             -0.564949        0.120336                -0.011978  \n",
       "PC25             -0.086659        0.020248                -0.005937  \n",
       "PC26             -0.264477       -0.044098                -0.278049  \n",
       "PC27             -0.146142        0.024166                -0.003982  \n",
       "PC28              0.223117        0.022636                 0.057201  \n",
       "PC29              0.022776        0.005131                -0.023158  \n",
       "PC30              0.034580        0.012879                 0.010476  \n",
       "PC31              0.002349       -0.000305                -0.001678  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Entrenamiento modelo PCA con escalado de los datos\n",
    "# ==============================================================================\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA())\n",
    "pca_pipe.fit(df)\n",
    "\n",
    "# Se extrae el modelo entrenado del pipeline\n",
    "modelo_pca = pca_pipe.named_steps['pca']\n",
    "# Se combierte el array a dataframe para añadir nombres a los ejes.\n",
    "pd.DataFrame(\n",
    "    data    = modelo_pca.components_,\n",
    "    columns = df.columns,\n",
    "    index   = ['PC1', 'PC2', 'PC3', 'PC4','PC5', 'PC6', 'PC7', 'PC8','PC9', 'PC10', 'PC11', 'PC12','PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19','PC20','PC21', 'PC22', 'PC23', 'PC24','PC25','PC26', 'PC27', 'PC28', 'PC29','PC30','PC31']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graficar varianza por componente\n",
    "percent_variance = np.round(modelo_pca.explained_variance_ratio_* 100, decimals =2)\n",
    "columns = ['PC1', 'PC2', 'PC3', 'PC4','PC5', 'PC6', 'PC7', 'PC8','PC9', 'PC10', 'PC11', 'PC12','PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19','PC20','PC21', 'PC22', 'PC23', 'PC24','PC25','PC26', 'PC27', 'PC28', 'PC29','PC30','PC31']\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.bar(x= range(1,32), height=percent_variance, tick_label=columns)\n",
    "plt.xticks(np.arange(modelo_pca.n_components_) + 1)\n",
    "\n",
    "plt.ylabel('Componente principal')\n",
    "plt.xlabel('Por. varianza explicada')\n",
    "plt.title('Porcentaje de varianza explicada por cada componente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graficar varianza por la suma acumulada de los componente\n",
    "percent_variance_cum = np.cumsum(percent_variance)\n",
    "columns = ['PC1', 'PC2', 'PC3', 'PC4','PC5', 'PC6', 'PC7', 'PC8','PC9', 'PC10', 'PC11', 'PC12','PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19','PC20','PC21', 'PC22', 'PC23', 'PC24','PC25','PC26', 'PC27', 'PC28', 'PC29','PC30','PC31']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.bar(x= range(1,32), height=percent_variance_cum, tick_label=columns)\n",
    "plt.ylabel('Percentate of Variance Explained')\n",
    "plt.xlabel('Principal Component Cumsum')\n",
    "plt.title('PCA Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC22</th>\n",
       "      <th>PC23</th>\n",
       "      <th>PC24</th>\n",
       "      <th>PC25</th>\n",
       "      <th>PC26</th>\n",
       "      <th>PC27</th>\n",
       "      <th>PC28</th>\n",
       "      <th>PC29</th>\n",
       "      <th>PC30</th>\n",
       "      <th>PC31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>9.225770</td>\n",
       "      <td>2.116196</td>\n",
       "      <td>-0.948109</td>\n",
       "      <td>-3.695778</td>\n",
       "      <td>-1.256280</td>\n",
       "      <td>1.419117</td>\n",
       "      <td>2.194974</td>\n",
       "      <td>-0.315737</td>\n",
       "      <td>-0.156946</td>\n",
       "      <td>-0.889455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169643</td>\n",
       "      <td>0.081284</td>\n",
       "      <td>0.085396</td>\n",
       "      <td>-0.176795</td>\n",
       "      <td>-0.156546</td>\n",
       "      <td>-0.187547</td>\n",
       "      <td>-0.262048</td>\n",
       "      <td>-0.033109</td>\n",
       "      <td>0.043898</td>\n",
       "      <td>-0.046916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>2.655802</td>\n",
       "      <td>-3.784776</td>\n",
       "      <td>-0.502825</td>\n",
       "      <td>-1.123938</td>\n",
       "      <td>0.551107</td>\n",
       "      <td>0.019273</td>\n",
       "      <td>-0.099645</td>\n",
       "      <td>0.385282</td>\n",
       "      <td>-0.711683</td>\n",
       "      <td>1.049263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067161</td>\n",
       "      <td>-0.089242</td>\n",
       "      <td>-0.216010</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>-0.171406</td>\n",
       "      <td>-0.043313</td>\n",
       "      <td>0.182637</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>-0.003854</td>\n",
       "      <td>-0.002299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>5.892492</td>\n",
       "      <td>-1.005579</td>\n",
       "      <td>-0.487149</td>\n",
       "      <td>-0.942486</td>\n",
       "      <td>-0.191711</td>\n",
       "      <td>0.541332</td>\n",
       "      <td>-0.660969</td>\n",
       "      <td>0.058983</td>\n",
       "      <td>0.024004</td>\n",
       "      <td>0.456603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215265</td>\n",
       "      <td>-0.051629</td>\n",
       "      <td>-0.073947</td>\n",
       "      <td>0.109567</td>\n",
       "      <td>0.175480</td>\n",
       "      <td>-0.005903</td>\n",
       "      <td>0.045610</td>\n",
       "      <td>0.047553</td>\n",
       "      <td>0.001533</td>\n",
       "      <td>0.001115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>7.135401</td>\n",
       "      <td>10.318716</td>\n",
       "      <td>-3.339501</td>\n",
       "      <td>-0.085947</td>\n",
       "      <td>-2.938456</td>\n",
       "      <td>3.062748</td>\n",
       "      <td>1.380734</td>\n",
       "      <td>1.150379</td>\n",
       "      <td>-1.405498</td>\n",
       "      <td>-1.123232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262375</td>\n",
       "      <td>-0.195118</td>\n",
       "      <td>-0.125393</td>\n",
       "      <td>0.157425</td>\n",
       "      <td>0.082025</td>\n",
       "      <td>-0.290911</td>\n",
       "      <td>0.166242</td>\n",
       "      <td>0.042973</td>\n",
       "      <td>-0.071320</td>\n",
       "      <td>-0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>4.129423</td>\n",
       "      <td>-1.905579</td>\n",
       "      <td>1.454000</td>\n",
       "      <td>-2.880175</td>\n",
       "      <td>0.365289</td>\n",
       "      <td>-1.243428</td>\n",
       "      <td>-1.073155</td>\n",
       "      <td>0.717646</td>\n",
       "      <td>-0.263770</td>\n",
       "      <td>0.354929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081634</td>\n",
       "      <td>-0.022214</td>\n",
       "      <td>0.140422</td>\n",
       "      <td>-0.017348</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.044767</td>\n",
       "      <td>0.037922</td>\n",
       "      <td>-0.035519</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>0.020683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PC1        PC2       PC3       PC4       PC5       PC6  \\\n",
       "id                                                                      \n",
       "842302    9.225770   2.116196 -0.948109 -3.695778 -1.256280  1.419117   \n",
       "842517    2.655802  -3.784776 -0.502825 -1.123938  0.551107  0.019273   \n",
       "84300903  5.892492  -1.005579 -0.487149 -0.942486 -0.191711  0.541332   \n",
       "84348301  7.135401  10.318716 -3.339501 -0.085947 -2.938456  3.062748   \n",
       "84358402  4.129423  -1.905579  1.454000 -2.880175  0.365289 -1.243428   \n",
       "\n",
       "               PC7       PC8       PC9      PC10  ...      PC22      PC23  \\\n",
       "id                                                ...                       \n",
       "842302    2.194974 -0.315737 -0.156946 -0.889455  ...  0.169643  0.081284   \n",
       "842517   -0.099645  0.385282 -0.711683  1.049263  ... -0.067161 -0.089242   \n",
       "84300903 -0.660969  0.058983  0.024004  0.456603  ...  0.215265 -0.051629   \n",
       "84348301  1.380734  1.150379 -1.405498 -1.123232  ...  0.262375 -0.195118   \n",
       "84358402 -1.073155  0.717646 -0.263770  0.354929  ... -0.081634 -0.022214   \n",
       "\n",
       "              PC24      PC25      PC26      PC27      PC28      PC29  \\\n",
       "id                                                                     \n",
       "842302    0.085396 -0.176795 -0.156546 -0.187547 -0.262048 -0.033109   \n",
       "842517   -0.216010  0.008557 -0.171406 -0.043313  0.182637  0.031919   \n",
       "84300903 -0.073947  0.109567  0.175480 -0.005903  0.045610  0.047553   \n",
       "84348301 -0.125393  0.157425  0.082025 -0.290911  0.166242  0.042973   \n",
       "84358402  0.140422 -0.017348  0.001300  0.044767  0.037922 -0.035519   \n",
       "\n",
       "              PC30      PC31  \n",
       "id                            \n",
       "842302    0.043898 -0.046916  \n",
       "842517   -0.003854 -0.002299  \n",
       "84300903  0.001533  0.001115  \n",
       "84348301 -0.071320 -0.019300  \n",
       "84358402  0.007297  0.020683  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proyección de las observaciones de entrenamiento\n",
    "# ==============================================================================\n",
    "proyecc = pca_pipe.transform(X=df)\n",
    "proyecc = pd.DataFrame(\n",
    "    proyecc,\n",
    "    columns =['PC1', 'PC2', 'PC3', 'PC4','PC5', 'PC6', 'PC7', 'PC8','PC9', 'PC10', 'PC11', 'PC12','PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19','PC20','PC21', 'PC22', 'PC23', 'PC24','PC25','PC26', 'PC27', 'PC28', 'PC29','PC30','PC31']\n",
    ",\n",
    "    index   = df.index\n",
    ")\n",
    "proyecc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PC1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.093933e-15</td>\n",
       "      <td>8.355288e-17</td>\n",
       "      <td>-2.624409e-17</td>\n",
       "      <td>1.095496e-17</td>\n",
       "      <td>-2.590789e-17</td>\n",
       "      <td>7.370370e-17</td>\n",
       "      <td>-5.242651e-17</td>\n",
       "      <td>1.050890e-16</td>\n",
       "      <td>2.597983e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.490036e-13</td>\n",
       "      <td>-8.527758e-14</td>\n",
       "      <td>-8.217452e-14</td>\n",
       "      <td>-6.575203e-15</td>\n",
       "      <td>8.388753e-15</td>\n",
       "      <td>1.346256e-16</td>\n",
       "      <td>-3.799320e-17</td>\n",
       "      <td>-3.323444e-18</td>\n",
       "      <td>7.719543e-17</td>\n",
       "      <td>6.221487e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC2</th>\n",
       "      <td>-9.092163e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.740896e-16</td>\n",
       "      <td>-3.836713e-16</td>\n",
       "      <td>5.038700e-16</td>\n",
       "      <td>1.389833e-16</td>\n",
       "      <td>1.953009e-18</td>\n",
       "      <td>-2.198503e-16</td>\n",
       "      <td>2.979797e-16</td>\n",
       "      <td>-1.338954e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>4.367378e-12</td>\n",
       "      <td>-2.011483e-12</td>\n",
       "      <td>-2.587366e-12</td>\n",
       "      <td>1.077439e-13</td>\n",
       "      <td>2.381284e-13</td>\n",
       "      <td>1.081576e-14</td>\n",
       "      <td>-6.551746e-16</td>\n",
       "      <td>-6.371432e-17</td>\n",
       "      <td>-2.974050e-17</td>\n",
       "      <td>-5.693968e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC3</th>\n",
       "      <td>-8.265105e-17</td>\n",
       "      <td>-9.991997e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.097829e-15</td>\n",
       "      <td>-9.910497e-17</td>\n",
       "      <td>8.414561e-18</td>\n",
       "      <td>7.229724e-16</td>\n",
       "      <td>3.082443e-15</td>\n",
       "      <td>-3.895923e-15</td>\n",
       "      <td>3.351169e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.979415e-11</td>\n",
       "      <td>8.106865e-12</td>\n",
       "      <td>5.788516e-11</td>\n",
       "      <td>4.883234e-12</td>\n",
       "      <td>3.275392e-12</td>\n",
       "      <td>-1.187238e-13</td>\n",
       "      <td>3.451837e-14</td>\n",
       "      <td>6.675485e-17</td>\n",
       "      <td>1.532060e-17</td>\n",
       "      <td>-8.226010e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC4</th>\n",
       "      <td>2.618001e-17</td>\n",
       "      <td>4.071357e-16</td>\n",
       "      <td>-1.159767e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.639513e-15</td>\n",
       "      <td>-2.919381e-15</td>\n",
       "      <td>-1.791613e-14</td>\n",
       "      <td>-5.309534e-14</td>\n",
       "      <td>6.273692e-14</td>\n",
       "      <td>-3.183292e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>9.523119e-10</td>\n",
       "      <td>-5.555568e-10</td>\n",
       "      <td>-2.997981e-10</td>\n",
       "      <td>-2.233367e-11</td>\n",
       "      <td>5.494443e-11</td>\n",
       "      <td>2.281816e-13</td>\n",
       "      <td>-5.053257e-13</td>\n",
       "      <td>1.699520e-16</td>\n",
       "      <td>5.089255e-17</td>\n",
       "      <td>1.670943e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC5</th>\n",
       "      <td>-1.091059e-17</td>\n",
       "      <td>-5.215120e-16</td>\n",
       "      <td>9.274384e-17</td>\n",
       "      <td>-2.503383e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.573520e-14</td>\n",
       "      <td>1.495285e-13</td>\n",
       "      <td>4.278284e-13</td>\n",
       "      <td>-5.734970e-13</td>\n",
       "      <td>3.530769e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.248812e-09</td>\n",
       "      <td>4.356365e-09</td>\n",
       "      <td>4.200247e-09</td>\n",
       "      <td>4.582091e-10</td>\n",
       "      <td>-2.271370e-10</td>\n",
       "      <td>-5.696126e-12</td>\n",
       "      <td>5.132196e-12</td>\n",
       "      <td>-2.794784e-15</td>\n",
       "      <td>-1.365549e-16</td>\n",
       "      <td>-3.823013e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC6</th>\n",
       "      <td>2.590243e-17</td>\n",
       "      <td>-1.367167e-16</td>\n",
       "      <td>-8.188004e-18</td>\n",
       "      <td>2.545233e-15</td>\n",
       "      <td>-2.529353e-14</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-4.001972e-13</td>\n",
       "      <td>-9.842515e-13</td>\n",
       "      <td>1.302292e-12</td>\n",
       "      <td>-8.507777e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.217467e-08</td>\n",
       "      <td>-7.505944e-09</td>\n",
       "      <td>-9.873976e-09</td>\n",
       "      <td>-1.504249e-09</td>\n",
       "      <td>4.162292e-10</td>\n",
       "      <td>3.636900e-12</td>\n",
       "      <td>-1.271085e-11</td>\n",
       "      <td>5.307241e-15</td>\n",
       "      <td>2.265490e-16</td>\n",
       "      <td>1.189234e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC7</th>\n",
       "      <td>-7.379042e-17</td>\n",
       "      <td>-4.516055e-18</td>\n",
       "      <td>-6.874162e-16</td>\n",
       "      <td>1.757535e-14</td>\n",
       "      <td>-1.458916e-13</td>\n",
       "      <td>3.932649e-13</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-4.154737e-11</td>\n",
       "      <td>4.078681e-11</td>\n",
       "      <td>-2.155149e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>2.950934e-07</td>\n",
       "      <td>-1.361853e-07</td>\n",
       "      <td>-1.642616e-07</td>\n",
       "      <td>-9.156690e-09</td>\n",
       "      <td>1.325911e-08</td>\n",
       "      <td>4.480998e-10</td>\n",
       "      <td>-1.409235e-10</td>\n",
       "      <td>5.176823e-14</td>\n",
       "      <td>1.106933e-15</td>\n",
       "      <td>-1.337865e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC8</th>\n",
       "      <td>5.202349e-17</td>\n",
       "      <td>2.085031e-16</td>\n",
       "      <td>-2.937592e-15</td>\n",
       "      <td>5.057802e-14</td>\n",
       "      <td>-4.094689e-13</td>\n",
       "      <td>9.484438e-13</td>\n",
       "      <td>4.078606e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.534528e-10</td>\n",
       "      <td>-1.912381e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.199323e-06</td>\n",
       "      <td>-1.222855e-06</td>\n",
       "      <td>-7.232498e-07</td>\n",
       "      <td>-1.393353e-07</td>\n",
       "      <td>6.845701e-08</td>\n",
       "      <td>1.051178e-11</td>\n",
       "      <td>-1.222316e-09</td>\n",
       "      <td>5.282611e-13</td>\n",
       "      <td>4.454945e-14</td>\n",
       "      <td>6.388140e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC9</th>\n",
       "      <td>-1.044787e-16</td>\n",
       "      <td>-2.811840e-16</td>\n",
       "      <td>3.672604e-15</td>\n",
       "      <td>-5.922839e-14</td>\n",
       "      <td>5.442578e-13</td>\n",
       "      <td>-1.244475e-12</td>\n",
       "      <td>-3.966120e-11</td>\n",
       "      <td>-6.469209e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.265051e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.469920e-06</td>\n",
       "      <td>2.462428e-06</td>\n",
       "      <td>1.806434e-06</td>\n",
       "      <td>3.938853e-07</td>\n",
       "      <td>9.263867e-08</td>\n",
       "      <td>-2.047293e-09</td>\n",
       "      <td>1.500895e-09</td>\n",
       "      <td>-1.549059e-12</td>\n",
       "      <td>-8.952223e-14</td>\n",
       "      <td>2.134086e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC10</th>\n",
       "      <td>-2.641102e-17</td>\n",
       "      <td>1.213175e-16</td>\n",
       "      <td>-3.126760e-15</td>\n",
       "      <td>2.981034e-14</td>\n",
       "      <td>-3.318647e-13</td>\n",
       "      <td>8.052010e-13</td>\n",
       "      <td>2.072504e-11</td>\n",
       "      <td>1.869907e-10</td>\n",
       "      <td>-7.174145e-10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.545741e-07</td>\n",
       "      <td>-7.792468e-07</td>\n",
       "      <td>-2.846936e-06</td>\n",
       "      <td>-3.595156e-07</td>\n",
       "      <td>-1.561482e-07</td>\n",
       "      <td>1.045032e-08</td>\n",
       "      <td>-1.998678e-09</td>\n",
       "      <td>2.239337e-12</td>\n",
       "      <td>4.734646e-14</td>\n",
       "      <td>1.337265e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC11</th>\n",
       "      <td>-1.096874e-17</td>\n",
       "      <td>1.083487e-15</td>\n",
       "      <td>-1.446907e-14</td>\n",
       "      <td>2.486570e-13</td>\n",
       "      <td>-1.809494e-12</td>\n",
       "      <td>3.839675e-12</td>\n",
       "      <td>1.177270e-10</td>\n",
       "      <td>8.140475e-10</td>\n",
       "      <td>-1.641793e-09</td>\n",
       "      <td>2.185458e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.264457e-05</td>\n",
       "      <td>-6.857261e-06</td>\n",
       "      <td>-4.328729e-06</td>\n",
       "      <td>-2.637865e-07</td>\n",
       "      <td>9.152286e-07</td>\n",
       "      <td>2.563639e-09</td>\n",
       "      <td>-7.736699e-09</td>\n",
       "      <td>2.836615e-12</td>\n",
       "      <td>1.528226e-13</td>\n",
       "      <td>2.986504e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         diagnosis   radius_mean  texture_mean  perimeter_mean     area_mean  \\\n",
       "PC1   1.000000e+00  9.093933e-15  8.355288e-17   -2.624409e-17  1.095496e-17   \n",
       "PC2  -9.092163e-15  1.000000e+00  8.740896e-16   -3.836713e-16  5.038700e-16   \n",
       "PC3  -8.265105e-17 -9.991997e-16  1.000000e+00    1.097829e-15 -9.910497e-17   \n",
       "PC4   2.618001e-17  4.071357e-16 -1.159767e-15    1.000000e+00  1.639513e-15   \n",
       "PC5  -1.091059e-17 -5.215120e-16  9.274384e-17   -2.503383e-15  1.000000e+00   \n",
       "PC6   2.590243e-17 -1.367167e-16 -8.188004e-18    2.545233e-15 -2.529353e-14   \n",
       "PC7  -7.379042e-17 -4.516055e-18 -6.874162e-16    1.757535e-14 -1.458916e-13   \n",
       "PC8   5.202349e-17  2.085031e-16 -2.937592e-15    5.057802e-14 -4.094689e-13   \n",
       "PC9  -1.044787e-16 -2.811840e-16  3.672604e-15   -5.922839e-14  5.442578e-13   \n",
       "PC10 -2.641102e-17  1.213175e-16 -3.126760e-15    2.981034e-14 -3.318647e-13   \n",
       "PC11 -1.096874e-17  1.083487e-15 -1.446907e-14    2.486570e-13 -1.809494e-12   \n",
       "\n",
       "      smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "PC1     -2.590789e-17      7.370370e-17   -5.242651e-17         1.050890e-16   \n",
       "PC2      1.389833e-16      1.953009e-18   -2.198503e-16         2.979797e-16   \n",
       "PC3      8.414561e-18      7.229724e-16    3.082443e-15        -3.895923e-15   \n",
       "PC4     -2.919381e-15     -1.791613e-14   -5.309534e-14         6.273692e-14   \n",
       "PC5      2.573520e-14      1.495285e-13    4.278284e-13        -5.734970e-13   \n",
       "PC6      1.000000e+00     -4.001972e-13   -9.842515e-13         1.302292e-12   \n",
       "PC7      3.932649e-13      1.000000e+00   -4.154737e-11         4.078681e-11   \n",
       "PC8      9.484438e-13      4.078606e-11    1.000000e+00         6.534528e-10   \n",
       "PC9     -1.244475e-12     -3.966120e-11   -6.469209e-10         1.000000e+00   \n",
       "PC10     8.052010e-13      2.072504e-11    1.869907e-10        -7.174145e-10   \n",
       "PC11     3.839675e-12      1.177270e-10    8.140475e-10        -1.641793e-09   \n",
       "\n",
       "      symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "PC1    2.597983e-17  ...  1.490036e-13  -8.527758e-14    -8.217452e-14   \n",
       "PC2   -1.338954e-16  ...  4.367378e-12  -2.011483e-12    -2.587366e-12   \n",
       "PC3    3.351169e-15  ... -5.979415e-11   8.106865e-12     5.788516e-11   \n",
       "PC4   -3.183292e-14  ...  9.523119e-10  -5.555568e-10    -2.997981e-10   \n",
       "PC5    3.530769e-13  ... -6.248812e-09   4.356365e-09     4.200247e-09   \n",
       "PC6   -8.507777e-13  ...  1.217467e-08  -7.505944e-09    -9.873976e-09   \n",
       "PC7   -2.155149e-11  ...  2.950934e-07  -1.361853e-07    -1.642616e-07   \n",
       "PC8   -1.912381e-10  ...  1.199323e-06  -1.222855e-06    -7.232498e-07   \n",
       "PC9    7.265051e-10  ... -1.469920e-06   2.462428e-06     1.806434e-06   \n",
       "PC10   1.000000e+00  ...  9.545741e-07  -7.792468e-07    -2.846936e-06   \n",
       "PC11   2.185458e-09  ...  1.264457e-05  -6.857261e-06    -4.328729e-06   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "PC1  -6.575203e-15      8.388753e-15       1.346256e-16    -3.799320e-17   \n",
       "PC2   1.077439e-13      2.381284e-13       1.081576e-14    -6.551746e-16   \n",
       "PC3   4.883234e-12      3.275392e-12      -1.187238e-13     3.451837e-14   \n",
       "PC4  -2.233367e-11      5.494443e-11       2.281816e-13    -5.053257e-13   \n",
       "PC5   4.582091e-10     -2.271370e-10      -5.696126e-12     5.132196e-12   \n",
       "PC6  -1.504249e-09      4.162292e-10       3.636900e-12    -1.271085e-11   \n",
       "PC7  -9.156690e-09      1.325911e-08       4.480998e-10    -1.409235e-10   \n",
       "PC8  -1.393353e-07      6.845701e-08       1.051178e-11    -1.222316e-09   \n",
       "PC9   3.938853e-07      9.263867e-08      -2.047293e-09     1.500895e-09   \n",
       "PC10 -3.595156e-07     -1.561482e-07       1.045032e-08    -1.998678e-09   \n",
       "PC11 -2.637865e-07      9.152286e-07       2.563639e-09    -7.736699e-09   \n",
       "\n",
       "      concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "PC1          -3.323444e-18    7.719543e-17             6.221487e-17  \n",
       "PC2          -6.371432e-17   -2.974050e-17            -5.693968e-21  \n",
       "PC3           6.675485e-17    1.532060e-17            -8.226010e-17  \n",
       "PC4           1.699520e-16    5.089255e-17             1.670943e-16  \n",
       "PC5          -2.794784e-15   -1.365549e-16            -3.823013e-17  \n",
       "PC6           5.307241e-15    2.265490e-16             1.189234e-18  \n",
       "PC7           5.176823e-14    1.106933e-15            -1.337865e-16  \n",
       "PC8           5.282611e-13    4.454945e-14             6.388140e-17  \n",
       "PC9          -1.549059e-12   -8.952223e-14             2.134086e-16  \n",
       "PC10          2.239337e-12    4.734646e-14             1.337265e-18  \n",
       "PC11          2.836615e-12    1.528226e-13             2.986504e-17  \n",
       "\n",
       "[11 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Entrenamiento modelo PCA con escalado de los datos\n",
    "# ==============================================================================\n",
    "pca_pipe = make_pipeline(PCA(n_components=11))\n",
    "pca_pipe.fit(proyecc)\n",
    "\n",
    "# Se extrae el modelo entrenado del pipeline\n",
    "modelo_pca = pca_pipe.named_steps['pca']\n",
    "# Se combierte el array a dataframe para añadir nombres a los ejes.\n",
    "pd.DataFrame(\n",
    "    data    = modelo_pca.components_,\n",
    "    columns = df.columns,\n",
    "    index   = ['PC1', 'PC2', 'PC3', 'PC4','PC5', 'PC6', 'PC7', 'PC8','PC9','PC10','PC11']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelo_pca_proyectado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-c52b4a051aec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# graficar varianza por componente\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpercent_variance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelo_pca_proyectado\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'PC1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PC2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PC3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PC4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PC5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PC6'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PC7'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PC8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PC9'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PC10'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PC11'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'modelo_pca_proyectado' is not defined"
     ]
    }
   ],
   "source": [
    "# graficar varianza por componente\n",
    "percent_variance = np.round(modelo_pca_proyectado.explained_variance_ratio_* 100, decimals =2)\n",
    "columns = ['PC1', 'PC2', 'PC3', 'PC4','PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10','PC11']\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.bar(x= range(1,12), height=percent_variance, tick_label=columns)\n",
    "plt.xticks(np.arange(modelo_pca_proyectado.n_components_) + 1)\n",
    "\n",
    "plt.ylabel('Componente principal')\n",
    "plt.xlabel('Por. varianza explicada')\n",
    "plt.title('Porcentaje de varianza explicada por cada componente')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652875</td>\n",
       "      <td>2.532476</td>\n",
       "      <td>2.217509</td>\n",
       "      <td>2.255769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487071</td>\n",
       "      <td>-0.023844</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>-0.868632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363479</td>\n",
       "      <td>2.037232</td>\n",
       "      <td>0.939681</td>\n",
       "      <td>-0.397998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915895</td>\n",
       "      <td>1.451712</td>\n",
       "      <td>2.867380</td>\n",
       "      <td>4.910908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539341</td>\n",
       "      <td>1.371014</td>\n",
       "      <td>1.428491</td>\n",
       "      <td>-0.009563</td>\n",
       "      <td>-0.562429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
       "id                                                                     \n",
       "842302    1.297676  1.097064 -2.073335  1.269934  0.984375  1.568466   \n",
       "842517    1.297676  1.829821 -0.353632  1.685955  1.908708 -0.826962   \n",
       "84300903  1.297676  1.579888  0.456187  1.566503  1.558884  0.942210   \n",
       "84348301  1.297676 -0.768909  0.253732 -0.592687 -0.764464  3.283553   \n",
       "84358402  1.297676  1.750297 -1.151816  1.776573  1.826229  0.280372   \n",
       "\n",
       "               PC7       PC8       PC9      PC10      PC11  \n",
       "id                                                          \n",
       "842302    3.283515  2.652875  2.532476  2.217509  2.255769  \n",
       "842517   -0.487071 -0.023844  0.548144  0.001390 -0.868632  \n",
       "84300903  1.052926  1.363479  2.037232  0.939681 -0.397998  \n",
       "84348301  3.402909  1.915895  1.451712  2.867380  4.910908  \n",
       "84358402  0.539341  1.371014  1.428491 -0.009563 -0.562429  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proyección de las observaciones de entrenamiento\n",
    "# ==============================================================================\n",
    "proyecciones = pca_pipe.transform(X=df)\n",
    "proyecciones = pd.DataFrame(\n",
    "    proyecciones,\n",
    "    columns = ['PC1', 'PC2', 'PC3', 'PC4','PC5', 'PC6', 'PC7', 'PC8','PC9','PC10','PC11'],\n",
    "    index   = df.index\n",
    ")\n",
    "proyecciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Valores originales\n",
      "------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652875</td>\n",
       "      <td>2.532476</td>\n",
       "      <td>2.217509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-7.964178e-07</td>\n",
       "      <td>2.178526e-06</td>\n",
       "      <td>2.527181e-08</td>\n",
       "      <td>-2.180429e-08</td>\n",
       "      <td>9.018521e-12</td>\n",
       "      <td>3.451516e-13</td>\n",
       "      <td>7.703607e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487071</td>\n",
       "      <td>-0.023844</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.544011e-07</td>\n",
       "      <td>-7.532105e-07</td>\n",
       "      <td>-3.566487e-09</td>\n",
       "      <td>7.657498e-09</td>\n",
       "      <td>-3.357352e-12</td>\n",
       "      <td>-1.836744e-13</td>\n",
       "      <td>4.739360e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363479</td>\n",
       "      <td>2.037232</td>\n",
       "      <td>0.939681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.692345e-07</td>\n",
       "      <td>-2.148354e-07</td>\n",
       "      <td>5.109850e-09</td>\n",
       "      <td>2.439005e-09</td>\n",
       "      <td>-1.404872e-12</td>\n",
       "      <td>-1.366612e-13</td>\n",
       "      <td>6.185276e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915895</td>\n",
       "      <td>1.451712</td>\n",
       "      <td>2.867380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-2.057878e-06</td>\n",
       "      <td>4.359136e-06</td>\n",
       "      <td>4.114386e-08</td>\n",
       "      <td>-4.441305e-08</td>\n",
       "      <td>1.931039e-11</td>\n",
       "      <td>8.463621e-13</td>\n",
       "      <td>1.230792e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539341</td>\n",
       "      <td>1.371014</td>\n",
       "      <td>1.428491</td>\n",
       "      <td>-0.009563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>5.188612e-07</td>\n",
       "      <td>-2.801211e-07</td>\n",
       "      <td>-4.219069e-09</td>\n",
       "      <td>4.767521e-09</td>\n",
       "      <td>-3.080948e-12</td>\n",
       "      <td>-1.526756e-13</td>\n",
       "      <td>7.079961e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                          \n",
       "842302     1.297676     1.097064     -2.073335        1.269934   0.984375   \n",
       "842517     1.297676     1.829821     -0.353632        1.685955   1.908708   \n",
       "84300903   1.297676     1.579888      0.456187        1.566503   1.558884   \n",
       "84348301   1.297676    -0.768909      0.253732       -0.592687  -0.764464   \n",
       "84358402   1.297676     1.750297     -1.151816        1.776573   1.826229   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                            \n",
       "842302           1.568466          3.283515        2.652875   \n",
       "842517          -0.826962         -0.487071       -0.023844   \n",
       "84300903         0.942210          1.052926        1.363479   \n",
       "84348301         3.283553          3.402909        1.915895   \n",
       "84358402         0.280372          0.539341        1.371014   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  radius_worst  \\\n",
       "id                                            ...                 \n",
       "842302               2.532476       2.217509  ...      0.000031   \n",
       "842517               0.548144       0.001390  ...     -0.000012   \n",
       "84300903             2.037232       0.939681  ...     -0.000005   \n",
       "84348301             1.451712       2.867380  ...      0.000066   \n",
       "84358402             1.428491      -0.009563  ...     -0.000007   \n",
       "\n",
       "          texture_worst  perimeter_worst    area_worst  smoothness_worst  \\\n",
       "id                                                                         \n",
       "842302        -0.000015        -0.000014 -7.964178e-07      2.178526e-06   \n",
       "842517         0.000007         0.000005  4.544011e-07     -7.532105e-07   \n",
       "84300903       0.000005         0.000002  3.692345e-07     -2.148354e-07   \n",
       "84348301      -0.000035        -0.000029 -2.057878e-06      4.359136e-06   \n",
       "84358402       0.000006         0.000004  5.188612e-07     -2.801211e-07   \n",
       "\n",
       "          compactness_worst  concavity_worst  concave points_worst  \\\n",
       "id                                                                   \n",
       "842302         2.527181e-08    -2.180429e-08          9.018521e-12   \n",
       "842517        -3.566487e-09     7.657498e-09         -3.357352e-12   \n",
       "84300903       5.109850e-09     2.439005e-09         -1.404872e-12   \n",
       "84348301       4.114386e-08    -4.441305e-08          1.931039e-11   \n",
       "84358402      -4.219069e-09     4.767521e-09         -3.080948e-12   \n",
       "\n",
       "          symmetry_worst  fractal_dimension_worst  \n",
       "id                                                 \n",
       "842302      3.451516e-13             7.703607e-16  \n",
       "842517     -1.836744e-13             4.739360e-16  \n",
       "84300903   -1.366612e-13             6.185276e-16  \n",
       "84348301    8.463621e-13             1.230792e-16  \n",
       "84358402   -1.526756e-13             7.079961e-16  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Valores reconstruidos\n",
      "---------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>1.297676</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                          \n",
       "842302     1.297676     1.097064     -2.073335        1.269934   0.984375   \n",
       "842517     1.297676     1.829821     -0.353632        1.685955   1.908708   \n",
       "84300903   1.297676     1.579888      0.456187        1.566503   1.558884   \n",
       "84348301   1.297676    -0.768909      0.253732       -0.592687  -0.764464   \n",
       "84358402   1.297676     1.750297     -1.151816        1.776573   1.826229   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                            \n",
       "842302           1.568466          3.283515        2.652874   \n",
       "842517          -0.826962         -0.487072       -0.023846   \n",
       "84300903         0.942210          1.052926        1.363478   \n",
       "84348301         3.283553          3.402909        1.915897   \n",
       "84358402         0.280372          0.539340        1.371011   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  radius_worst  \\\n",
       "id                                            ...                 \n",
       "842302               2.532475       2.217515  ...      1.886690   \n",
       "842517               0.548144       0.001392  ...      1.805927   \n",
       "84300903             2.037231       0.939685  ...      1.511870   \n",
       "84348301             1.451707       2.867383  ...     -0.281464   \n",
       "84358402             1.428493      -0.009560  ...      1.298575   \n",
       "\n",
       "          texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "id                                                                       \n",
       "842302        -1.359293         2.303601    2.001237          1.307686   \n",
       "842517        -0.369203         1.535126    1.890489         -0.375612   \n",
       "84300903      -0.023974         1.347475    1.456285          0.527407   \n",
       "84348301       0.133984        -0.249939   -0.550021          3.394275   \n",
       "84358402      -1.466770         1.338539    1.220724          0.220556   \n",
       "\n",
       "          compactness_worst  concavity_worst  concave points_worst  \\\n",
       "id                                                                   \n",
       "842302             2.616665         2.109526              2.296076   \n",
       "842517            -0.430444        -0.146749              1.087084   \n",
       "84300903           1.082932         0.854974              1.955000   \n",
       "84348301           3.893397         1.989588              2.175786   \n",
       "84358402          -0.313395         0.613179              0.729259   \n",
       "\n",
       "          symmetry_worst  fractal_dimension_worst  \n",
       "id                                                 \n",
       "842302          2.750622                 1.937015  \n",
       "842517         -0.243890                 0.281190  \n",
       "84300903        1.152255                 0.201391  \n",
       "84348301        6.046041                 4.935010  \n",
       "84358402       -0.868353                -0.397100  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recostruccion de las proyecciones\n",
    "# ==============================================================================\n",
    "recostruccion = pca_pipe.inverse_transform(X=proyecciones)\n",
    "recostruccion = pd.DataFrame(\n",
    "                    recostruccion,\n",
    "                    columns = df.columns,\n",
    "                    index   = df.index\n",
    ")\n",
    "print('------------------')\n",
    "print('Valores originales')\n",
    "print('------------------')\n",
    "display(recostruccion.head())\n",
    "\n",
    "print('---------------------')\n",
    "print('Valores reconstruidos')\n",
    "print('---------------------')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Aplique al menos tres modelos de clasificación distintos. Para cada uno de los modelos escogidos, realice una optimización de los hiperparámetros. además, calcule las respectivas métricas. Concluya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# cargar datos\n",
    "df2 = pd.read_csv(os.path.join(\"data\",\"BC.csv\"), sep=\",\")\n",
    "df2['diagnosis'] = df2['diagnosis'] .replace({'M':1,'B':0}) # target "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(columns='diagnosis').values\n",
    "Y = df2['diagnosis'].values\n",
    "\n",
    "# split dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000, solver='newton-cg')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creando el modelo\n",
    "rlog = LogisticRegression(solver='newton-cg', max_iter=2000)\n",
    "rlog.fit(X_train, Y_train) # ajustando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9494505494505494"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlog.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores:\n",
      "\n",
      "originales:  [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "predicho:    [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "\n",
    "from metrics_classification import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true =  list(Y_test)\n",
    "y_pred = list(rlog.predict(X_test))\n",
    "\n",
    "print('Valores:\\n')\n",
    "print('originales: ', y_true)\n",
    "print('predicho:   ', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusion:\n",
      " \n",
      "[[64  5]\n",
      " [ 3 42]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metricas para los regresores : 'datos de pacientes'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.9304</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.9271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  recall  precision  fscore\n",
       "0    0.9298  0.9304     0.9244  0.9271"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo \n",
    "df_temp = pd.DataFrame(\n",
    "    {\n",
    "        'y':y_true,\n",
    "        'yhat':y_pred\n",
    "        }\n",
    ")\n",
    "\n",
    "df_metrics = summary_metrics(df_temp)\n",
    "print(\"\\nMetricas para los regresores : 'datos de pacientes'\")\n",
    "print(\"\")\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un principio se utilizó el solver ‘lbfgs’ pero daba métricas bajas prediciendo deficientemente, por lo que se optó por probar con el solver ‘newton-cg’. Este dio como resultado métricas mayores y predijo mejor.\n",
    "Cabe mencionar que se le aumentó el número de iteraciones porque no convergía, a pesar de esto, el warning sigue apareciendo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método 2: MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Creando el modelo\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train, Y_train) # ajustando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6329670329670329"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusion:\n",
      " \n",
      "[[69  0]\n",
      " [45  0]]\n"
     ]
    }
   ],
   "source": [
    "y_true2 =  list(Y_test)\n",
    "y_pred2 = list(clf.predict(X_test))\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metricas para los regresores : \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EstebanSaez\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3026</td>\n",
       "      <td>0.377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  recall  precision  fscore\n",
       "0    0.6053     0.5     0.3026   0.377"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp2 = pd.DataFrame(\n",
    "    {\n",
    "        'y':y_true2,\n",
    "        'yhat':y_pred2\n",
    "        }\n",
    ")\n",
    "\n",
    "df_metrics2 = summary_metrics(df_temp2)\n",
    "print(\"\\nMetricas para los regresores : \")\n",
    "print(\"\")\n",
    "df_metrics2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de los varios intentos para mejorar las métricas, moviendo todos los hiperparámetros no se pudo obtener un mejor resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método 3: K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Creando el modelo\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X_train, Y_train) # ajustando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de confusion:\n",
      " \n",
      "[[64  5]\n",
      " [10 35]]\n"
     ]
    }
   ],
   "source": [
    "y_true3 =  list(Y_test)\n",
    "y_pred3 = list(model.predict(X_test))\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true3,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metricas para los regresores : \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.8699</td>\n",
       "      <td>0.8593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  recall  precision  fscore\n",
       "0    0.8684  0.8527     0.8699  0.8593"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp3 = pd.DataFrame(\n",
    "    {\n",
    "        'y':y_true3,\n",
    "        'yhat':y_pred3\n",
    "        }\n",
    ")\n",
    "\n",
    "df_metrics3 = summary_metrics(df_temp3)\n",
    "print(\"\\nMetricas para los regresores : \")\n",
    "print(\"\")\n",
    "df_metrics3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el anterior modelo, se probó varios hiperparámetros, pero ninguno logró mejorar las métricas, ni siquiera probando con árbol de decisión.\n",
    "Por otro lado, probé distintas vecindarios pero resultó que con 1 daba el mejor resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los resultados obtenidos con estos 3 métodos de clasificación, se concluye que en este caso el mejor método esel logístico, ya que es el que mejor métricas arroja. Luego, el segundo mejor método es K-Nearest Neighbours ya que es el que le sigue en métricas al modelo logístico y finalmente el peor modelo viene siendo MLPClassifier ya que dio métricas bajas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
